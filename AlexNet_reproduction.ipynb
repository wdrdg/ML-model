{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wdrdg/ML-model/blob/main/AlexNet_reproduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXb0qEMzhVBw"
      },
      "source": [
        "# Import & Definition of our most effective model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IcZ48k8YGCi"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, Activation, MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.layers import BatchNormalization as normalization\n",
        "from keras.layers import concatenate,Dropout,Flatten\n",
        "\n",
        "from keras import optimizers,regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.initializers import he_normal\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "num_classes        = 10         #分成多少类\n",
        "batch_size         = 64         # 一个batch用64张图\n",
        "iterations         = 782        #一个epoch用782个batch\n",
        "epochs             = 50        #一共循环300个epoch        changed to 50 for now 0423\n",
        "DROPOUT=0.5                     # 每个神经元以50%的概率失效\n",
        "CONCAT_AXIS=3\n",
        "weight_decay=1e-4\n",
        "DATA_FORMAT='channels_last'     # Theano:'channels_first'  Tensorflow:'channels_last'\n",
        "log_filepath  = './alexnet'     #tensorbroad的文件储存的路径"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIgtE3nSaKgH",
        "outputId": "01dcac0e-aa51-4f08-cb0c-7d258244057e"
      },
      "source": [
        "def color_preprocessing(x_train,x_test):\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    mean = [125.307, 122.95, 113.865]\n",
        "    std  = [62.9932, 62.0887, 66.7048]\n",
        "    for i in range(3):\n",
        "        x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
        "        x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
        "    return x_train, x_test\n",
        "\n",
        "def scheduler(epoch):\n",
        "    if epoch < 100:\n",
        "        return 0.01\n",
        "    if epoch < 200:\n",
        "        return 0.001\n",
        "    return 0.0001\n",
        "\n",
        "# load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test  = keras.utils.to_categorical(y_test, num_classes)\n",
        "x_train, x_test = color_preprocessing(x_train, x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDS5yaOHcIyG"
      },
      "source": [
        "def alexnet(img_input,activation_func,is_normalized,has_overlap_pool,has_dropout,struct=[1,1,1,1,1], classes=10):\n",
        "    #struct defines the structure of alexnet; the ith element being '1' indicates that the ith convolutional layer is present\n",
        "    x = img_input\n",
        "    if struct[0]==1:\n",
        "      x = Conv2D(96,(11,11),strides=(4,4),padding='same',\n",
        "                activation=activation_func,kernel_initializer='uniform')(x)# valid\n",
        "      if is_normalized : \n",
        "        x = normalization()(x)   #added normalization\n",
        "      if has_overlap_pool:\n",
        "        x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same',data_format=DATA_FORMAT)(x)\n",
        "      else:\n",
        "        x = MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same',data_format=DATA_FORMAT)(x)\n",
        "\n",
        "    if struct[1]==1:\n",
        "      x = Conv2D(256,(5,5),strides=(1,1),padding='same',\n",
        "                activation=activation_func,kernel_initializer='uniform')(x)\n",
        "      if is_normalized : x = normalization()(x)   #added normalization\n",
        "      if has_overlap_pool:\n",
        "        x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same',data_format=DATA_FORMAT)(x)\n",
        "      else:\n",
        "        x = MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same',data_format=DATA_FORMAT)(x)\n",
        "\n",
        "    if struct[2]==1:\n",
        "      x = Conv2D(384,(3,3),strides=(1,1),padding='same',\n",
        "                activation=activation_func,kernel_initializer='uniform')(x) \n",
        "      if is_normalized : x = normalization()(x)   #added normalization\n",
        "\n",
        "\n",
        "    if struct[3]==1:\n",
        "      x = Conv2D(384,(3,3),strides=(1,1),padding='same',\n",
        "                activation=activation_func,kernel_initializer='uniform')(x) \n",
        "      if is_normalized : x = normalization()(x)   #added normalization\n",
        "\n",
        "    if struct[4]==1:\n",
        "      x = Conv2D(256,(3,3),strides=(1,1),padding='same',\n",
        "                activation=activation_func,kernel_initializer='uniform')(x)\n",
        "      if is_normalized : x = normalization()(x)   #added normalization\n",
        "      if has_overlap_pool: \n",
        "        x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same',data_format=DATA_FORMAT)(x)\n",
        "      else:\n",
        "        x = MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same',data_format=DATA_FORMAT)(x)\n",
        "    \n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(4096,activation=activation_func)(x)\n",
        "    if has_dropout: x = Dropout(0.5)(x)\n",
        "    x = Dense(4096,activation=activation_func)(x)\n",
        "    if has_dropout: x = Dropout(0.5)(x)\n",
        "    out = Dense(classes, activation='softmax')(x)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtxYtbNJcMXk",
        "outputId": "91bcd84f-e61d-478b-fdfe-7079951b015d"
      },
      "source": [
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,'relu',True,True,True)\n",
        "model=Model(img_input,output)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 96)          34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 96)          384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 21,627,658\n",
            "Trainable params: 21,624,906\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZwkrdFjhtDi"
      },
      "source": [
        "# Training our best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmdYIYGP3_tn"
      },
      "source": [
        "sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# set callback\n",
        "tb_cb = TensorBoard(log_dir=log_filepath, histogram_freq=0)\n",
        "change_lr = LearningRateScheduler(scheduler)\n",
        "cbks = [change_lr,tb_cb]\n",
        "\n",
        "# set data augmentation\n",
        "datagen = ImageDataGenerator(horizontal_flip=True,\n",
        "                             width_shift_range=0.125,\n",
        "                             height_shift_range=0.125,\n",
        "                             fill_mode='constant',cval=0.)\n",
        "\n",
        "#horizontal_flip=True Randomly flip inputs horizontally. 随机翻转\n",
        "# width_shift_range=0.125 水平平移，相对总宽度的比例\n",
        "#height_shift_range=0.125 垂直平移，相对总高度的比例\n",
        "#fill_mode='constant',cval=0 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k) 平移完用0来填充\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtMSdsK6cfgJ",
        "outputId": "23bfbb08-8ca0-4bb4-ebff-4613750852cb"
      },
      "source": [
        "sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# set callback\n",
        "tb_cb = TensorBoard(log_dir=log_filepath, histogram_freq=0)\n",
        "change_lr = LearningRateScheduler(scheduler)\n",
        "cbks = [change_lr,tb_cb]\n",
        "\n",
        "# set data augmentation\n",
        "datagen = ImageDataGenerator(horizontal_flip=True,\n",
        "                             width_shift_range=0.125,\n",
        "                             height_shift_range=0.125,\n",
        "                             fill_mode='constant',cval=0.)\n",
        "\n",
        "#horizontal_flip=True Randomly flip inputs horizontally. 随机翻转\n",
        "# width_shift_range=0.125 水平平移，相对总宽度的比例\n",
        "#height_shift_range=0.125 垂直平移，相对总高度的比例\n",
        "#fill_mode='constant',cval=0 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k) 平移完用0来填充\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# start training\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=iterations,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "model.save('alexnet.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 59s 33ms/step - loss: 1.8794 - accuracy: 0.3201 - val_loss: 1.3808 - val_accuracy: 0.4997\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.4182 - accuracy: 0.4898 - val_loss: 1.2620 - val_accuracy: 0.5478\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.2779 - accuracy: 0.5411 - val_loss: 1.1426 - val_accuracy: 0.5992\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.1862 - accuracy: 0.5763 - val_loss: 1.1079 - val_accuracy: 0.6084\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 25s 31ms/step - loss: 1.1214 - accuracy: 0.6042 - val_loss: 1.0277 - val_accuracy: 0.6437\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.0559 - accuracy: 0.6263 - val_loss: 1.0694 - val_accuracy: 0.6240\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.0205 - accuracy: 0.6415 - val_loss: 0.9816 - val_accuracy: 0.6520\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9871 - accuracy: 0.6530 - val_loss: 0.9238 - val_accuracy: 0.6760\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9575 - accuracy: 0.6621 - val_loss: 0.9177 - val_accuracy: 0.6772\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9214 - accuracy: 0.6769 - val_loss: 0.9528 - val_accuracy: 0.6640\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8962 - accuracy: 0.6839 - val_loss: 0.8793 - val_accuracy: 0.6990\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8705 - accuracy: 0.6945 - val_loss: 0.8889 - val_accuracy: 0.6864\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8304 - accuracy: 0.7093 - val_loss: 0.8427 - val_accuracy: 0.7147\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8032 - accuracy: 0.7189 - val_loss: 0.8916 - val_accuracy: 0.6922\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7950 - accuracy: 0.7224 - val_loss: 0.8929 - val_accuracy: 0.6898\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7741 - accuracy: 0.7333 - val_loss: 0.8635 - val_accuracy: 0.6944\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7495 - accuracy: 0.7374 - val_loss: 0.8487 - val_accuracy: 0.6986\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7362 - accuracy: 0.7402 - val_loss: 0.8292 - val_accuracy: 0.7141\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7114 - accuracy: 0.7481 - val_loss: 0.7997 - val_accuracy: 0.7217\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.6960 - accuracy: 0.7557 - val_loss: 0.7951 - val_accuracy: 0.7223\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.6838 - accuracy: 0.7578 - val_loss: 0.8082 - val_accuracy: 0.7236\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.6613 - accuracy: 0.7692 - val_loss: 0.8036 - val_accuracy: 0.7228\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.6483 - accuracy: 0.7715 - val_loss: 0.7826 - val_accuracy: 0.7317\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.6347 - accuracy: 0.7765 - val_loss: 0.7791 - val_accuracy: 0.7331\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.6164 - accuracy: 0.7844 - val_loss: 0.7863 - val_accuracy: 0.7326\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.5983 - accuracy: 0.7908 - val_loss: 0.7998 - val_accuracy: 0.7284\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.5904 - accuracy: 0.7931 - val_loss: 0.7635 - val_accuracy: 0.7393\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.5754 - accuracy: 0.7965 - val_loss: 0.7558 - val_accuracy: 0.7442\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.5611 - accuracy: 0.7997 - val_loss: 0.7744 - val_accuracy: 0.7416\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.5454 - accuracy: 0.8075 - val_loss: 0.7693 - val_accuracy: 0.7403\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.5263 - accuracy: 0.8138 - val_loss: 0.7901 - val_accuracy: 0.7399\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.5275 - accuracy: 0.8119 - val_loss: 0.7766 - val_accuracy: 0.7427\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.5106 - accuracy: 0.8182 - val_loss: 0.7689 - val_accuracy: 0.7421\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.5019 - accuracy: 0.8240 - val_loss: 0.7716 - val_accuracy: 0.7401\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.4716 - accuracy: 0.8319 - val_loss: 0.7806 - val_accuracy: 0.7430\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.4698 - accuracy: 0.8327 - val_loss: 0.7716 - val_accuracy: 0.7449\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.4702 - accuracy: 0.8335 - val_loss: 0.7793 - val_accuracy: 0.7448\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.4560 - accuracy: 0.8367 - val_loss: 0.7690 - val_accuracy: 0.7498\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.4352 - accuracy: 0.8469 - val_loss: 0.8104 - val_accuracy: 0.7416\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.4273 - accuracy: 0.8469 - val_loss: 0.7957 - val_accuracy: 0.7391\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.4087 - accuracy: 0.8525 - val_loss: 0.7762 - val_accuracy: 0.7500\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3958 - accuracy: 0.8591 - val_loss: 0.7928 - val_accuracy: 0.7434\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3892 - accuracy: 0.8577 - val_loss: 0.7967 - val_accuracy: 0.7481\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3836 - accuracy: 0.8655 - val_loss: 0.8157 - val_accuracy: 0.7475\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3759 - accuracy: 0.8660 - val_loss: 0.8262 - val_accuracy: 0.7438\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3656 - accuracy: 0.8705 - val_loss: 0.8011 - val_accuracy: 0.7468\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3562 - accuracy: 0.8729 - val_loss: 0.8117 - val_accuracy: 0.7517\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3473 - accuracy: 0.8737 - val_loss: 0.8307 - val_accuracy: 0.7450\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3292 - accuracy: 0.8831 - val_loss: 0.8428 - val_accuracy: 0.7460\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3310 - accuracy: 0.8810 - val_loss: 0.8379 - val_accuracy: 0.7439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9hzbk5Jt8l1"
      },
      "source": [
        "# Visualize History for Loss.\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "def err_from_acc(accs):\n",
        "  return [1.0-acc for acc in accs]\n",
        "\n",
        "print('The lowest error achieved on our model is: ' + str(np.min(err_from_acc(history.history['val_accuracy']))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gCbdb57h2RJ"
      },
      "source": [
        "# Ablation Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZx5kb93j9Bx"
      },
      "source": [
        "#Testing the accuracy drop from removing the first convolutional layer\n",
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,'relu',True,True,True,struct=[0,1,1,1,1])\n",
        "model=Model(img_input,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "history_rem1 = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=iterations,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#displaying the result\n",
        "print('Accuracy improvement in having_all_layers vs not_having_first is: ' + \n",
        "     str(100*np.min(err_from_acc(history_rem1.history['val_accuracy'])) - 100*np.min(err_from_acc(history.history['val_accuracy']))) \n",
        "     + ' percent' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMQLQY_OS0EN"
      },
      "source": [
        "#Testing the accuracy drop from removing the second convolutional layer\n",
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,'relu',True,True,True,struct=[1,0,1,1,1])\n",
        "model=Model(img_input,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "history_rem2 = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=iterations,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#displaying the result\n",
        "print('Accuracy improvement in having_all_layers vs not_having_second is: ' + \n",
        "     str(100*np.min(err_from_acc(history_rem2.history['val_accuracy'])) - 100*np.min(err_from_acc(history.history['val_accuracy']))) \n",
        "     + ' percent' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7mawWPSS09d"
      },
      "source": [
        "#Testing the accuracy drop from removing the third convolutional layer\n",
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,'relu',True,True,True,struct=[1,1,0,1,1])\n",
        "model=Model(img_input,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "history_rem3 = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=iterations,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#displaying the result\n",
        "print('Accuracy improvement in having_all_layers vs not_having_third is: ' + \n",
        "     str(100*np.min(err_from_acc(history_rem3.history['val_accuracy'])) - 100*np.min(err_from_acc(history.history['val_accuracy']))) \n",
        "     + ' percent' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xIX4HN7S1TR"
      },
      "source": [
        "#Testing the accuracy drop from removing the fourth convolutional layer\n",
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,'relu',True,True,True,struct=[1,1,1,0,1])\n",
        "model=Model(img_input,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "history_rem4 = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=iterations,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#displaying the result\n",
        "print('Accuracy improvement in having_all_layers vs not_having_fourth is: ' + \n",
        "     str(100*np.min(err_from_acc(history_rem4.history['val_accuracy'])) - 100*np.min(err_from_acc(history.history['val_accuracy']))) \n",
        "     + ' percent' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ7eeetxS2Gm"
      },
      "source": [
        "#Testing the accuracy drop from removing the fifth convolutional layer\n",
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,'relu',True,True,True,struct=[1,1,1,1,0])\n",
        "model=Model(img_input,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "history_rem5 = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=iterations,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#displaying the result\n",
        "print('Accuracy improvement in having_all_layers vs not_having_fifth is: ' + \n",
        "     str(100*np.min(err_from_acc(history_rem5.history['val_accuracy'])) - 100*np.min(err_from_acc(history.history['val_accuracy']))) \n",
        "     + ' percent' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jfdDF7sjz3x"
      },
      "source": [
        "# Reproducing the experiments in the AlexNet paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KxpSIZkBiQnJ",
        "outputId": "5d90e282-2a16-42eb-cdb1-a8926f0b5f0d"
      },
      "source": [
        "#3.1 ReLU-activated CNN takes less time to reach 25% training error than CNNs with saturating non-linearity\n",
        "#First define Alexnet but with tanh activation function\n",
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,'tanh',True,True,True)   #Activation, lrn, Overlap, Dropout\n",
        "model=Model(img_input,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "history_tanh = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=iterations,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#displaying the result\n",
        "plt.title('training with relu vs. tanh')\n",
        "plt.plot(err_from_acc(history.history['val_accuracy']))\n",
        "plt.plot(err_from_acc(history_tanh.history['val_accuracy']))\n",
        "plt.ylabel('error')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['relu', 'tanh'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 27s 33ms/step - loss: 2.2798 - accuracy: 0.2652 - val_loss: 1.6780 - val_accuracy: 0.4049\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.6288 - accuracy: 0.3984 - val_loss: 1.6066 - val_accuracy: 0.4179\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.5269 - accuracy: 0.4463 - val_loss: 1.4354 - val_accuracy: 0.4846\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.4494 - accuracy: 0.4789 - val_loss: 1.4709 - val_accuracy: 0.4716\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.3926 - accuracy: 0.4952 - val_loss: 1.2790 - val_accuracy: 0.5371\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.3332 - accuracy: 0.5217 - val_loss: 1.3073 - val_accuracy: 0.5370\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.3124 - accuracy: 0.5295 - val_loss: 1.2750 - val_accuracy: 0.5531\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.2807 - accuracy: 0.5411 - val_loss: 1.2394 - val_accuracy: 0.5596\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.2515 - accuracy: 0.5542 - val_loss: 1.2402 - val_accuracy: 0.5670\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.2163 - accuracy: 0.5665 - val_loss: 1.1759 - val_accuracy: 0.5801\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.1964 - accuracy: 0.5703 - val_loss: 1.1531 - val_accuracy: 0.5975\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.1776 - accuracy: 0.5813 - val_loss: 1.1341 - val_accuracy: 0.6055\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 25s 31ms/step - loss: 1.1500 - accuracy: 0.5946 - val_loss: 1.1307 - val_accuracy: 0.6019\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.1209 - accuracy: 0.6022 - val_loss: 1.1609 - val_accuracy: 0.5863\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.1137 - accuracy: 0.6065 - val_loss: 1.0946 - val_accuracy: 0.6150\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.0813 - accuracy: 0.6178 - val_loss: 1.1059 - val_accuracy: 0.6179\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.0606 - accuracy: 0.6259 - val_loss: 1.0976 - val_accuracy: 0.6119\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.0418 - accuracy: 0.6305 - val_loss: 1.0350 - val_accuracy: 0.6455\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.0178 - accuracy: 0.6412 - val_loss: 1.0289 - val_accuracy: 0.6455\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.0238 - accuracy: 0.6419 - val_loss: 1.0379 - val_accuracy: 0.6453\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9986 - accuracy: 0.6488 - val_loss: 0.9836 - val_accuracy: 0.6543\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9888 - accuracy: 0.6564 - val_loss: 0.9634 - val_accuracy: 0.6642\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9665 - accuracy: 0.6592 - val_loss: 0.9691 - val_accuracy: 0.6586\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9534 - accuracy: 0.6672 - val_loss: 0.9874 - val_accuracy: 0.6613\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9456 - accuracy: 0.6705 - val_loss: 1.0105 - val_accuracy: 0.6508\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9178 - accuracy: 0.6792 - val_loss: 0.9964 - val_accuracy: 0.6620\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9173 - accuracy: 0.6760 - val_loss: 0.9929 - val_accuracy: 0.6672\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9099 - accuracy: 0.6806 - val_loss: 0.9890 - val_accuracy: 0.6596\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.9003 - accuracy: 0.6879 - val_loss: 0.9678 - val_accuracy: 0.6690\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8868 - accuracy: 0.6882 - val_loss: 0.9530 - val_accuracy: 0.6738\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8729 - accuracy: 0.6918 - val_loss: 0.9602 - val_accuracy: 0.6707\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8646 - accuracy: 0.6966 - val_loss: 0.9530 - val_accuracy: 0.6725\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8593 - accuracy: 0.6985 - val_loss: 0.9575 - val_accuracy: 0.6751\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8452 - accuracy: 0.7013 - val_loss: 0.9241 - val_accuracy: 0.6807\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8322 - accuracy: 0.7083 - val_loss: 0.9690 - val_accuracy: 0.6709\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8386 - accuracy: 0.7076 - val_loss: 0.9211 - val_accuracy: 0.6840\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8182 - accuracy: 0.7140 - val_loss: 0.9031 - val_accuracy: 0.6832\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8098 - accuracy: 0.7147 - val_loss: 0.8867 - val_accuracy: 0.6912\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7958 - accuracy: 0.7233 - val_loss: 0.8740 - val_accuracy: 0.7003\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7948 - accuracy: 0.7249 - val_loss: 0.8845 - val_accuracy: 0.6969\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.7950 - accuracy: 0.7220 - val_loss: 0.9111 - val_accuracy: 0.6843\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7788 - accuracy: 0.7274 - val_loss: 0.9348 - val_accuracy: 0.6788\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7749 - accuracy: 0.7288 - val_loss: 0.9283 - val_accuracy: 0.6826\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7638 - accuracy: 0.7321 - val_loss: 0.9035 - val_accuracy: 0.6895\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7522 - accuracy: 0.7330 - val_loss: 0.9261 - val_accuracy: 0.6859\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7438 - accuracy: 0.7428 - val_loss: 0.9647 - val_accuracy: 0.6790\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7364 - accuracy: 0.7435 - val_loss: 0.8900 - val_accuracy: 0.6970\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7255 - accuracy: 0.7451 - val_loss: 0.9060 - val_accuracy: 0.6974\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7241 - accuracy: 0.7454 - val_loss: 0.8758 - val_accuracy: 0.7066\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.7168 - accuracy: 0.7492 - val_loss: 0.8861 - val_accuracy: 0.6966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdZ3RVddaA8WenQwglhR6SCAldQEMRBDuiCFhRBAtjHcU+Rcd5baOjY5lRZ7CLiiKIHRQFUWmKQJDeOySUFEglCSn7/XBuMGAq3Jubsn9rZSWn7xP07vy7qCrGGGPM8Xy8HYAxxpjayRKEMcaYMlmCMMYYUyZLEMYYY8pkCcIYY0yZLEEYY4wpkyUI4xUi8pqI/J+7z/UEERksIpsqOB4tIioifh56/mMi8oEn7l0biMi7IvKkt+Mwv+eR/6BN/SYiO4GbVXXuid5DVW/3xLmeoKoLgc4l2+54/7pMRB4DOqnqOG/HYjzLShDG7Tz1l3R9JSK+3o7BmLJYgjDVIiLvAx2AmSKSLSJ/KVXFcpOI7AZ+cJ37sYjsF5EMEVkgIt1L3edotYKInC0iiSLygIgki8g+ERl/gueGichMEckUkWUi8qSILCrnXd4TkQdcP7dzvcOdru2OInJQRHxKnlne+5e65VgR2S0iqSLycAW/w3dF5FURmSUiOcA5ItJWRD4VkRQR2SEid5dz7dFYSu3bKSLnl3Fuf9fv37fUvstEZLXr534ikuD6XR0QkX+XF3Op64cBfwOudr3/Ktf+8SKyQUSyRGS7iNx2fMzl/Zu5tBCRr13XLxGRjpXFYjzPEoSpFlW9DtgNjFDVJqr6bKnDZwFdgQtd298AsUBL4FdgSgW3bg00A9oBNwETRaTFCZw7EchxnXOD66s884GzS8W+HRhSanuhqhaXvqCS9z8TpyrqPOAREelawbOvBZ4CQoCfgZnAKtc7nQfcKyIXln955VR1Cc7v4tzjnvuh6+eXgJdUtSnQEZhehXt+C/wT+Mj1/r1ch5KBS4CmwHjgPyJyWqlLK/v3vQZ4HGgBbMX53RgvswRh3OkxVc1R1VwAVZ2kqlmqmg88BvQSkWblXFsAPKGqBao6C8imVL1/Vc51/aV8BfCoqh5W1fXAexXEOx84U0R8cBLDs8Ag17GzXMer43FVzVXVVTgf9r0qOPdLVf3JlYB6AhGq+oSqHlHV7cCbOB+aJ2sqMAZAREKAi137wPk9dhKRcFXNVtVfTvQhqvq1qm5Tx3xgDjC41CmV/ft+rqpLVbUQ5w+J3icai3EfSxDGnfaU/CAiviLyjIhsE5FMYKfrUHg516a5PhxKHAaaVPPcCJyOF3tKHSv98zFUdRvOX9i9cT7MvgL2ikhnTixB7K9i/MfHFQW0FZH0ki+capxW1Xx+WT4ELheRQOBy4FdV3eU6dhMQB2x0VcddcqIPEZGLROQXV7VcOk4iKv1vXdm/b3V+d6aGWGOiORHlTQFcev+1wCjgfJzk0Aw4BIgH40oBCoH2wGbXvshKrpkPXAkEqGqSiMzHqZZqAaws5xp3TIFc+h57gB2qGluF63KAxiUbrlJTRLkPUV0vIruAizi2eglV3QKMcZWgLgc+EZEwVc2pRuy4ks+nwPU4JaMCEfkCz/5bmxpgJQhzIg4Ap1RyTgiQD6ThfKD909NBqWoR8BnwmIg0FpEuOB9aFZkPTAAWuLbnubYXue5Xlqq8f3UsBbJE5K8i0shV+uohIn3LOHczECQiw0XEH/g7EFjJ/T8E7sGpRvu4ZKeIjBORCFc1V7prd3EZ1x/vABDtSiwAAa4YUoBCEbkIGFqF+5hazhKEORFPA393VYf8qZxzJgO7gCRgPXDC9dvVNAGntLIfeB+nvj2/gvPn4ySzkgSxCCehLSj3iqq9f5W5EtElOFVdO4BU4C2c9zj+3AzgDtfxJJwSReLx5x1nKk6V2Q+qmlpq/zBgnYhk4zRYX1PSfuTqoTT497cCfksyaSLyq6pmAXfjNHIfwimpzKgkJlMHiC0YZOozEfkX0FpVK+rNZIwpg5UgTL0iIl1E5FRx9MNpiP3c23EZUxdZI7Wpb0JwqlTa4tSVvwB86dWIjKmjrIrJGGNMmayKyRhjTJnqTRVTeHi4RkdHezsMY4ypU5YvX56qqmWOpak3CSI6OpqEhARvh2GMMXWKayBlmayKyRhjTJksQRhjjCmTRxOEiAwTkU0islVEHiznnNEisl5E1onIh6X23yAiW1xfNsjJGGNqmMfaIFyTiE0ELsCZCmCZiMxwTcFcck4s8BAwSFUPiUhL1/5Q4FEgHmdisOWuaw95Kl5jTMNVUFBAYmIieXl53g7FY4KCgmjfvj3+/v5VvsaTjdT9gK2uue0RkWk4s3uuL3XOLcDEkg9+VU127b8Q+E5VD7qu/Q5n3pipGGOMmyUmJhISEkJ0dDQi9W8SWlUlLS2NxMREYmJiqnydJ6uY2nHsnPeJrn2lxQFxIvKTay75YdW4FhG51bVkYkJKSoobQzfGNCR5eXmEhYXVy+QAICKEhYVVu4Tk7UZqP5wlKc/GWfXqTRFpXtWLVfUNVY1X1fiIiHKnxDfGmErV1+RQ4kTez5MJIoljF2tp79pXWiIww7UM4Q6cue5jq3itexQVwJz/g/TdHrm9McbUVZ5MEMuAWBGJEZEAnPV1j58j/gtci8aLSDhOldN2YDYwVERauBY2H+ra534Ze2D5uzB1DORne+QRxhjjDk2a1OxKrB5LEK71ZyfgfLBvAKar6joReUJERrpOm42z6Mh64Efgz6qa5mqc/gdOklmGs9j5QY8EGnoKXPkOJK+Hz2+D4qosqGWMMZ6hqhTXks8hj7ZBqOosVY1T1Y6q+pRr3yOqOsP1s6rq/araTVV7quq0UtdOUtVOrq93PBknsefDhU/Dxq/gh3949FHGGHO8nTt30rlzZ66//np69OjBP/7xD/r27cupp57Ko48++rvz582bxyWXXHJ0e8KECbz77rtuj6vezMV00vrfBikbYNG/IaIz9LrG2xEZY7zg8ZnrWL8306337Na2KY+O6F7hOVu2bOG9994jMzOTTz75hKVLl6KqjBw5kgULFjBkyBC3xlQV3u7FVHuIwMXPQ/RgmHEX7Fnq7YiMMQ1IVFQUAwYMYM6cOcyZM4c+ffpw2mmnsXHjRrZs2eKVmKwEUZqvP4yeDG+eC9OuhVt+gOYdvB2VMaYGVfaXvqcEBwcDThvEQw89xG233VbuuX5+fse0U3hqBLiVII7XOBSu/QgK861nkzGmxl144YVMmjSJ7GznsycpKYnk5ORjzomKimL9+vXk5+eTnp7O999/75FYrARRlojOTs+mD6+CeU/DhU95OyJjTAMxdOhQNmzYwBlnnAE4XVs/+OADWrZsefScyMhIRo8eTY8ePYiJiaFPnz4eiaXerEkdHx+vbl8w6J2LobgQbprj3vsaY2qVDRs20LVrV2+H4XFlvaeILFfV+LLOtyqmikR0hpSNUE+SqDHGVIcliIqEd4a8DMhOrvxcY4ypZyxBVCSis/M9ZaN34zDGGC+wBFGRiC7O99TN3o3DGGO8wBJERUJaQ2BTK0EYYxokSxAVEXE1VG/ydiTGGFPjLEFUJtwShDHGs9LT03nllVdO+Pqzzz4bt3fzxxJE5SI6Q04yHPbMbOPGGHOyCcJTLEFUpqQnkzVUG2M85MEHH2Tbtm307t2b++67j/POO4/TTjuNnj178uWXXwLOlOBdu3bllltuoXv37gwdOpTc3Nyj9/j444/p168fcXFxLFy40C1x2VQblSnd1bXDAO/GYozxvG8ehP1r3HvP1j3homfKPfzMM8+wdu1aVq5cSWFhIYcPH6Zp06akpqYyYMAARo501ljbsmULU6dO5c0332T06NF8+umnjBs3DoDCwkKWLl3KrFmzePzxx5k7d+5Jh20JojLNOoBfI0ixEoQxxvNUlb/97W8sWLAAHx8fkpKSOHDgAAAxMTH07t0bgNNPP52dO3ceve7yyy8vc//JsARRGR8fCI+1rq7GNBQV/KVfE6ZMmUJKSgrLly/H39+f6Ojoo9N5BwYGHj3P19f3mCqmkmO+vr4UFha6JRZrg6iKiC7WBmGM8ZiQkBCysrIAyMjIoGXLlvj7+/Pjjz+ya9cur8VlJYiqiIiDNdOdtSECm3g7GmNMPRMWFsagQYPo0aMHffv2ZePGjfTs2ZP4+Hi6dOnitbg8miBEZBjwEuALvKWqzxx3/EbgOSDJtet/qvqW61gRUNJStFtVR3oy1gqVnnKj3WleC8MYU399+OGHlZ6zdu3aoz//6U9/OvrzvHnzjv4cHh5e+9sgRMQXmAhcACQCy0RkhqquP+7Uj1R1Qhm3yFXV3p6Kr1rCS3oybbIEYYxpMDzZBtEP2Kqq21X1CDANGOXB53lOaAz4+EOqjag2xjQcnkwQ7YA9pbYTXfuOd4WIrBaRT0QkstT+IBFJEJFfROTSsh4gIre6zklISUlxY+jH8fWHsE425YYx9Vh9WV2zPCfyft7uxTQTiFbVU4HvgPdKHYtyLYN3LfCiiHQ8/mJVfUNV41U1PiIiwrORRsRZV1dj6qmgoCDS0tLqbZJQVdLS0ggKCqrWdZ5spE4CSpcI2vNbYzQAqppWavMt4NlSx5Jc37eLyDygD7DNU8FWKqILbJgJBXngX71fsjGmdmvfvj2JiYl4tCbCy4KCgmjfvn21rvFkglgGxIpIDE5iuAanNHCUiLRR1X2uzZHABtf+FsBhVc0XkXBgEKWSh1eEx4EWQ9pWaN3Dq6EYY9zL39+fmJgYb4dR63gsQahqoYhMAGbjdHOdpKrrROQJIEFVZwB3i8hIoBA4CNzourwr8LqIFONUgz1TRu+nmnW0q+smSxDGmAbBo+MgVHUWMOu4fY+U+vkh4KEyrvsZ6OnJ2KotrBOIjzVUG2MaDG83Utcd/kHQItoShDGmwbAEUR0RXSxBGGMaDEsQ1REe5zRSF7lnpkRjjKnNLEFUR0QXKC6AQzu8HYkxxnicJYjqiIhzvtuAOWNMA2AJojrCSxJEOe0QRQWQ5r2xfMYY406WIKojMASaRZadIIqL4ZPxMLE/5KbXfGzGGONmliCqKzyu7Fldf3zKmYqjuMB6Ohlj6gVLENUV0QVSNjslhhKrp8PC5yF2qLOdssE7sRljjBtZgqiuiDgozIUM10zmiQnw5QSIOhNGvw9+jawEYYypF2xN6uoqmZMpZRP4+MLUMdC0DYye7Iy2tmnBjTH1hJUgqqukJ9PeX2HqNVCQC2OmQXCYsz+iKyRbgjDG1H2WIKqrcSgEt4QFz8GBdXDVO9Cy62/HIzpD1l7Iy/BejMYY4waWIE5ERGcoLoShT0LsBccdK6mC2lzzcRljjBtZG8SJGPBH6HgODLjj98daliSIDRDZt2bjMsYYN7IEcSK6DHe+ytI8CvyCrCeTMabOsyomd/PxhfBY68lkjKnzLEF4gvVkMsbUA5YgPCGiM2QmQl6mtyMxxpgTZgnCE0p6MqVu8W4cxhhzEjyaIERkmIhsEpGtIvJgGcdvFJEUEVnp+rq51LEbRGSL6+sGT8bpdiXjImxOJmNMHeaxXkwi4gtMBC4AEoFlIjJDVdcfd+pHqjrhuGtDgUeBeECB5a5rD3ki1ryCIlShUYCve27YPAp8A62h2hhTp3myBNEP2Kqq21X1CDANGFXFay8EvlPVg66k8B0wzBNBJh46TI9HZzNjVZL7burr5+rJZF1djTF1lycTRDtgT6ntRNe+410hIqtF5BMRiazOtSJyq4gkiEhCSkrKCQXZtlkjggP9WLnHzYv8RHSxnkzGmDrN243UM4FoVT0Vp5TwXnUuVtU3VDVeVeMjIiJOKAAfH6FXZHNW7PZAgsjYDfnZ7r2vMcbUEE8miCQgstR2e9e+o1Q1TVXzXZtvAadX9Vp36h3ZnM0HssjJL3TfTSM6O99TbU4mY0zd5MkEsQyIFZEYEQkArgFmlD5BRNqU2hwJlHT7mQ0MFZEWItICGOra5xF9IptTrLAmyY0zsB7tyWTVTMaYusljvZhUtVBEJuB8sPsCk1R1nYg8ASSo6gzgbhEZCRQCB4EbXdceFJF/4CQZgCdU9aCnYu0V2RyAlXvSGXBKmHtu2iIGfPwtQRhj6iyPTtanqrOAWcfte6TUzw8BD5Vz7SRgkifjKxEaHEBUWGNW7HZjL1rryWSMqeO83Uhda/SObO6hnkw2WM4YUzdZgnDpE9mcA5n57MvIdd9NI7pA+m44kuO+expjTA2xBOHSu0MLAFa6s7trRGdAbU4mY0ydZAnCpWubEAJ8fdxbzWQ9mYwxdZglCJdAP1+6tW3KCncmiNBTwMfPEoQxpk6yBFFK78jmrEnMoLCo2D039PWHsE7Wk8kYUydZgiilT4fm5BYUselAlvtuaj2ZjDF1lCWIUnqXGjDnNhFd4NBOKHBj7yhjjKkBliBK6RDamNDgAOvJZIwxWII4hoi4f8Dc0Z5M1g5hjKlbLEEcp3dkc7amZJOVV+CeG4Z2dPVksnYIY0zdYgniOL0jm6MKqxPdNLOrX4CTJKwEYYypYyxBHKeXRxqqO9tYCGNMnWMJ4jjNGvlzSkSwe2d2jegCB7dDQZ777mmMMR7m0em+66rekc1ZsDkFVUVETv6GLbuAFsOUK8Ev0PlZi6G4CHx84ay/QtTAk3+OMca4kZUgytCnQwtSs4+QeMhNYxeiB0PUIDiSDbmHID/LKU0UF0HyRvh4PBz22HpIxhhzQqwEUYY+pdohIkMbn/wNm7SE8bPKPrZvFbx5LnzzV7jizZN/ljHGuImVIMrQuXUIgX5untm1PG16wZA/w5rpsGGm559njDFVZAmiDP6+PvRs16xmEgTA4AegdU/46j7ISauZZxpjTCU8miBEZJiIbBKRrSLyYAXnXSEiKiLxru1oEckVkZWur9c8GWdZekc2Z21SBgXumtm1Ir7+cNnrkJsOs/7k+ecZY0wVeCxBiIgvMBG4COgGjBGRbmWcFwLcAyw57tA2Ve3t+rrdU3GWp3eH5uQXFrNxnxtndq1Iq+5w9oOw7jNY93nNPNMYYyrgyRJEP2Crqm5X1SPANGBUGef9A/gXUKsGCZTM7LpijxvHQ1Rm0L3Qtg98/QBkp9Tcc40xpgyeTBDtgD2lthNd+44SkdOASFX9uozrY0RkhYjMF5HBZT1ARG4VkQQRSUhJce8HarvmjWgZEshPW1Pdet8K+frBpa9BfjZ8dS+o1tyzjTHmOF5rpBYRH+DfwANlHN4HdFDVPsD9wIci0vT4k1T1DVWNV9X4iIgId8fHZX3aMXdDMnvTa3Ath5Zd4NyHYeNXkDDJkoQxxms8mSCSgMhS2+1d+0qEAD2AeSKyExgAzBCReFXNV9U0AFVdDmwD4jwYa5nGDYhCVZmyZFfNPviMCc7guq/vhw9HQ9q2mn2+Mcbg2QSxDIgVkRgRCQCuAWaUHFTVDFUNV9VoVY0GfgFGqmqCiES4GrkRkVOAWGC7B2MtU2RoY87v2ooPl+wmr6Co5h7s4wvXfQ5Dn4Jdi+GVAfDDU3DkcM3FYIxp8DyWIFS1EJgAzAY2ANNVdZ2IPCEiIyu5fAiwWkRWAp8At6uqV+aiuHFQNIcOFzBj1d6afbCvPwycABOWQbdRsOBZeKU/bPzaqp2MMTVCtJ582MTHx2tCQoLb76uqDHtxIX6+wld3nemeyftOxI6FMOvPzsJDccPgkhehaRvvxGKMqTdEZLmqxpd1rNIShDgiKzuvvhIRbhgYzbq9mSTsqsEur8eLGQy3L4ShT8L2+U6105pPvBePMabeqzRBqFPEKGemuYbh0j5tadbIn3d/3undQHz9YeBdcPsiCOsEn94EH99o03MYYzyiqm0Qv4pIX49GUos1DvDj6r6RfLt2P/syarDLa3nCO8EfZsN5j8CGr5zSxKZvvR2VMaaeqWqC6A8sFpFtIrJaRNaIyGpPBlbbXOfq8vrBLzXc5bU8vn7OJH+3/uhMJz71avhyAhQVeDsyY0w9UdX1IC70aBR1QEmX16lL93DXubEE+ft6OyRH655wyw8w72lY9B/wC4Lhz3s7KmNMPVClEoSq7gKaAyNcX81d+xqUGwdGczDnCDNrustrZfwC4fzHYODdsOxNWPa2tyMyxtQDVUoQInIPMAVo6fr6QETu8mRgtdEZHcOIa9WEd3/eSa3sHnz+YxB7IXzzF9ixwNvRGGPquKq2QdwE9FfVR1T1EZxpMW7xXFi1k4hw48AY1u3NZLk3u7yWx8cXrnjL6eE0/Xo4WOODz40x9UhVE4QApeeaKHLta3Au7dOWpkF+vOPtLq/lCWoKY6Y6P08dA3mZ3o3HGFNnVTVBvAMsEZHHROQxnHmTGmRFd0mX19lr93Mgs1YtYfGb0FNg9GRI2wqf3gzFNTiPlDGm3qjKSGofnIQwHjjo+hqvqi96OLZaa9yAKIpU+XDJbm+HUr6YIXDRs7BlNsx9zNvRGGPqoEq7uapqsYhMdK3N8GsNxFTrRYUFc1ZcBFOX7mbCuZ3w9/XashoV63sTJK+Hn1+GyH7QdYS3IzLG1CFV/WT7XkSuEK/NVFf7XH9GFMlZ+cxet9/boVRs2DPOWIlZf7H2CGNMtVQ1QdwGfAzki0imiGSJSIP+tDkrriWRoY2YvLiWDwfx9YdLXoKsffDjU96OxhhTh1S1DWKYqvqoaoCqNlXVEFX93RKgDYmvjzCufxRLdxxk4/5anivbn+5UNy19A/aucP/98zJhxQfWGG5MPVOV2VyLgf/VQCx1zuj4SAL9fHi/tpciwJnYLzgCZt4DRYXuu68qzLwbvrwTNtuEgcbUJ9YGcRJaBAcwoldbPl+RRGZeLZ8kL6iZ0x6xb5UzHYe7rPkE1n0OCKz80H33NcZ4XXXaIKZjbRC/c/0ZURw+UsRnyxO9HUrlul8GnS6AH56EjKSTv19GInz9AET2hwF/dEoQ2Sknf19jTK1Q1QTRDLgReNLV9tAduMBTQdUlp7ZvTq/I5rz/y67aOT9TaSLOTK/FRfDtX0/uXsXF8MUdUFwIl70Gfa5zfl4z3T2xGmO8rqoJYiLO/EtjXNtZWLvEUdcPiGJbSg4/b6sDK7u1iIaz/gIbZsKmb078Pktfhx3zYdg/nZHbrbpB2z6wYorTLmGMqfOqvGCQqt4J5AGo6iEgoLKLRGSYiGwSka0i8mAF510hIioi8aX2PeS6bpOI1Or1KIaf2obQ4AAmL97p7VCqZuBd0LIbzPozHMmp/vXJG+G7RyFuGJx2w2/7e4+F5HVOO4cxps6raoIoEBFfQAFEJAIorugC1/kTgYuAbsAYEelWxnkhwD3AklL7ugHX4FRlDQNecd2vVgry92V0fCTfrT9AUnotWJK0Mr7+cMmLkLEHPrquemtaFx6Bz26BwCYw8r9OtVWJHleAb4A1VhtTT1Q1QbwMfA60FJGngEXAPyu5ph+wVVW3q+oRYBowqozz/gH8C1fpxGUUME1V81V1B7DVdb9aa2z/Dijw4ZI60OUVoEN/J0nsXAivDYKdi6p23fx/wf7VMOJlZ6nT0hqHQpfhTjtEYb77YzbG1Kiqrig3BfgL8DSwD7hUVT+u5LJ2wJ5S24mufUeJyGlApKp+Xd1rXdffKiIJIpKQkuLd3jORoY05r0tLpi3dU/u7vJaIHw83zwX/xvDeCJj3TPmD3fKz4df3YdG/ofc46HpJ2ef1Hge5h06ufcMYUytUeZY5Vd2oqhNV9X+quuFkH+waof1v4IETvYeqvqGq8aoaHxERcbIhnbQJ58aSnlvAw5+vrf09mkq06QW3zYeeo511rSePgsx9zrH8LGecw7Sx8FxHmDEBIrrAsKfLv1/HcyCkjVUzGVMPVDqb60lIAiJLbbd37SsRAvQA5rnG37UGZojIyCpcWyv1jmzO/RfE8dzsTQzuFM7ovpGVX1QbBIbA5a/DKWc54xpeG+SMbdj2AxTmQZPWTmN090shcgD4VPB3hY8v9LoGfnoJsvZDSOuaew9jjFt5cp7qZUCsiMSISABOo/OMkoOqmqGq4aoararROGtOjFTVBNd514hIoIjEALHAUg/G6ja3n9WRgR3DeHTGOrYmZ3k7nOrpfS3cOh+aR8HelU5SGP8t3L8BLn4WogZWnByO3mcsaDGs/sjzMRtjPMZjCUJVC4EJwGxgAzBdVdeJyBOuUkJF167DGbm9HvgWuFNV68RMcL4+wn+u7k2jAF8mfLiCvII6EfZvIuLg1h/hgZKkcEbVkkJp4bHQvp+NiTCmjvPoSjeqOktV41S1o6o+5dr3iKrOKOPcs12lh5Ltp1zXdVbVOtXi2appEC9c1YuN+7P456yTbq6pm/qMhdRNkGRrTBlTV9XSpdDqvnO6tOTmM2OYvHhX7V9UyBO6XwZ+jWDlB1W/Jmu/0way4DnPxWWMqTJLEB70l2Fd6NmuGX/5ZHXdGEDnTkHNnCVO13wKBZW8e36208X25T6w7C2Y/5zTg8oY41WWIDwowM+H/47pQ2FRMfdOW0FhUYWDz+ufPmMhPwPeOBtmPwxbvjt2ao/iIvh1Mvz3dKeLbexQGPUKFOXDljleC9sY47AE4WHR4cE8eVkPlu08xGcran1PXfeKOQuGv+CMuF76Bky5Ev4VDe9eAj/+E147E2bcBS2i4KbvYPR7ThfZ4AhnMkFjjFd5chyEcbm0dzveXLCD1+Zv48rT2uPj00DWXRKBvjc7X0cOw+7FsP1H2D7PmbKjRQyMngxdR/42p5OPL3S5BFZPd6qm/Bt59RWMacgsQdQAEeGPZ3fkrqkrmLP+AMN6NMDBYwGNodN5zhdAbjoENAHfMv4T7DoClr8D236ELhfXbJzGmKOsiqmGXNSjNVFhjXl1/ra6Mw2HJzVqXnZyAIgZ4jRyb/hdb2hjTA2yBFFD/Hx9uG1IR1btSWfx9jqwsJA3+fpD54th0ywoqiMTHxpTD1mCqEGXn9aOiJBAXp23zduh1H5dR0JeBuxY4O1IjGmwLEHUoCB/X246M4aFW1JZm5Th7XBqt47ngH+w9WYyxossQdSwsf07EBLkx6vzrRRRIf9GEDcUNn5V/hoVxhiPsgRRw0KC/LluQAaRxxUAACAASURBVBTfrNnHjtQTWA+6Iek6EnJSYM+Sys81xridJQgvGD8oBj9fH95YsN3bodRusReAbyCst95MxniDJQgviAgJZHR8ez5dnkhyZl7lFzRUgSHOuIkNM23acGO8wBKEl9w6uCOFxcW8/dMOb4dSu3UdAZmJsNemDTemplmC8JIOYY255NS2TPllNxm51te/XHHDwMfPejMZ4wWWILzo9rM6kp1fyFsLrS2iXI1DIXqw0w5h1UzG1ChLEF7UrW1TRvVuy+vzt7M9Jdvb4dRe3UbCwW2Q3EBX5zPGSyxBeNnDw7sS6OfDI1+uszmaytN5OCA2N5MxNcxmc/WyliFB/OnCzjw6Yx1frd7HiF5tvR1S7RPSCjqcASumlLM6nUJRIRQXQnGBM39TyeC6+D9AZN8aDdeY+kI8+VeriAwDXgJ8gbdU9Znjjt8O3AkUAdnAraq6XkSigQ3AJtepv6jq7RU9Kz4+XhMSEtz7AjWkqFgZNXERyZn5fP/AWYQE+Xs7pNpn1Ufw1b3lj6r29Xcas338XD/7Q34mFByGES9D7zE1G68xdYSILFfV+DKPeSpBiIgvsBm4AEgElgFjVHV9qXOaqmqm6+eRwB2qOsyVIL5S1R5VfV5dThAAq/akc+krP3HDGdE8NrK7t8OpHw4fhI9vcCb8G3QPnPeosyCRMeaoihKEJ9sg+gFbVXW7qh4BpgGjSp9QkhxcgoEGWwnfK7I5Y/t3YPLinTaRn7s0DoVxnznVTD+9BNPGQn6W55+r6qyId2in559ljAd5MkG0A/aU2k507TuGiNwpItuAZ4G7Sx2KEZEVIjJfRAaX9QARuVVEEkQkISUlxZ2xe8Wfh3YhNDiAv3+xluLiBpsr3cvXHy75D1z8PGyZA28PhUO7PPe84mL4+gH47BaYdBEctIGQpu7yei8mVZ2oqh2BvwJ/d+3eB3RQ1T7A/cCHItK0jGvfUNV4VY2PiIiouaA9pFljf/52cVdW7kln6rLd3g6nful3C4z7BDKT4M1zYPcv7n9GcRHMvBsS3obe46AwF94bCel7Kr/WmFrIkwkiCYgstd3eta8804BLAVQ1X1XTXD8vB7YBcR6Ks1a5rE87+seE8uy3m0jNzvd2OPVLx3Ph5h+gUQuYPAo2znLfvYsK4Ys/wor3YchfYNT/4LrPnUWP3hsBmfvc9yxjaognE8QyIFZEYkQkALgGOKYju4jEltocDmxx7Y9wNXIjIqcAsUCDGG4sIjx5aQ9y8gu5c8qv7M+wyfzcKrwT/GEOtOwGH42DFR+c/D2LCuDTm2D1R3Du3+Hch0EE2vaBcZ86U5ZPHgnZdb8a1DQsHksQqloITABm43RZna6q60TkCVePJYAJIrJORFbiVCXd4No/BFjt2v8JcLuqHvRUrLVNbKsQnr68J6sS07ngP/P5dHmiDaJzp+AwuGEmxAyBL++ERS+Wf+7+tTB1DDzVFt4ZDj8+7fSKKhmPUZgP06+H9V/A0KdgyJ+PvT6yL1w73almmjzK6VlVHdkpsPpjp4RiTA3z6DiImlTXu7mWZWdqDn/6eBUJuw5xftdW/PPyHrQMCfJ2WPVH4RH4/DZY9xkMvAvOfwJ8XH8zpWyGeU87xwKbObPKHlgL+1eDFoNvALTv65QeEpc6jeD9bin/Wdt+hA+vhpZd4fovoVHzyuPb9C3MmOCUQGKHwpXvQGAT97y7MS5eGQdR0+pjggBnEN07P+3g2dmbaBzgyxOjejDi1DaIiLdDqx+Ki+Hbv8LSN6DXGBj8J1j4AqyeBn6NYMAfYeAEp90CIDfdaeDeuRB2/QRp22HoP+D0Gyp+DsDmOTDtWghp7YzL6HMd+JeR8I/kwOyHYfk70Lqns7LevKehVQ+nNNK0jXt/B6ZBswRRD2xNzuaBj1c5A+p6t+X5q3rh5+v1Tmj1gyoseA5+fMrZ9guCvjfDmfdBcHjl11YnWe9cBHMfd0odTVrBGROccRolJYPE5U4X2YPbYdDdcM7D4BfoJJePb3QS1diPoVW3E3pVY45nCaKeKCwq5n8/buXFuVsY068D/7ysh5Uk3GnlVKca6Yw7oakH58RSdUogC56HHfOdD/3+fwQU5j/rPPuy1yD6zGOv27cKpox2pg8ZPRk6nuO5GE2DYQminvnXtxt5dd42HrggjrvOi638AlN7JSY4iWLzN852z9Fw8XPlt1FkJMKUqyB1M4x4CfqMq7lYTb1kCaKeUVUemL6Kz1Yk8dyVp3JVfGTlF5na7cA6Z8xE1MDKz83LgOk3wPYfnbEdA+501u6urDRZVAha5FRZGeNSUYKw6b7rIBHhmStOJTkrn4c+W0PLpkGcFVf3R5I3aK2qMUFjUDOnHeLn/8KS12HKFRDRxWlQP/Vq8G/027kZSbD1O9jyHWyfDwU5EHqKc37Lrs73iC4QHnvyiSMj0eny2+EMGPpk9dpmTK1kJYg6LCuvgKtf/4WdaTl8dOsZ9GzfzNshmZpWeMTpirt4otMFt3EYnD7eWRdjy1xIXuec17Q9xJ4PwRGQshGSNzoN4eqaPt03ANqe5pRgogZCZD8nEVVV8gb44ArI2u/c86LnoP+t7n9f43ZWxVSPHcjM4/JXfia/sJjP7xhIZGhjb4dkvEHV6SH1yyuw6RtnXYwOA5zxE7EXOKWE4/+iL8yHtK1Owti7EnYvhr0rnIWXxMfpVhszxBnf0SK6/GfvXgIfjnZKIGM/cbrkbp7tjCK3hvRazxJEPbc1OYsrXl1MWHAAU28dQKumNpiuQcvaDwHBEBhS/WuP5EDiMti1GHb/7Iz5UIXTrochf/p9765N3zjdb5u2g+s+cxJJfpYza25mEtzyI4R1dMdbGQ+xBNEAJOw8yA2TlhLWJJApN/e3koRxj8y9zhiRXyc7pZK+N8Oge6FJBPz6Psy8B9r0ctpESo8ZObQT3jwXGoXCzXOrNnK8ph3aBXuWwilnQZOWnnlGTiocToOIzp65vxtYgmggVu5J54ZJSwny92HKzf3p1PIE/oI0piyHdjpjNFZNdUaYdzoXNsyEjuc5YzLKmgJk50/OJIUxZzkjwH1rSZ+Y9D2w8HlnosaS6rRTzoYeV0LXS6rX9lIeVSepfvd/UJAHd/7idA6ohSxBNCCb9mcx7u0lFBUrk//Qjx7trOHauFHqFqeNYe2nzpiNURPBL6D885e/56yRMeAOGPZ0zcVZlsy9sPDf8Ot7zgf46Tc4SWHrXFjzMaTvAt9AiLsQel4FXYaf2BK1qVudktWuRdBhoNN5IGqgkyRrYc8uSxANzM7UHMa+tYTM3AImje9L3+hQb4dk6pucNGdJ16p84H3zICx51eld5RfozGibewhyDzo/BzaB4f9xZr71SKypzmDEhElOD6s+18HgB6B5qfFDqpC03EkUaz+DnGRoFw8jX656F+TCI/DzSzD/OWe6lqFPQJ/rnY4Dcx6Ga6ZCl4s9844nwRJEA7Q3PZdxby9hb3our18Xz2kdmrMz9TDbU7PZkZrDztQcEg/lMvzUNtw4MNqm7DCeU1QIH98AG7+CgBBo3MJpm2gc6nzfsxSy9sJ5j8AZd/02o6475KbDpAudkk/va52G9op6ZJXEu/ZTmP03yEt32lyG/LnsiRXBWUlwx3xngsXk9dBtFFz0rDMpIzgz/r422OkAcOcSCKhd7YOWIBqo1Ox8rn97KRv2Z1L6n1kE2jZrREiQHxv3ZzGmXyRPjOqBv03+ZzypqMBZI/x4uekw4y7YMAM6nQ+XvV75JIlVfd4HVziz7o77zGmMro7DB50P/VUfQlgnZ2qTkvmxiouc+677wmmLyUmGkLYw/IWySwk7F8G7w53VBs99+OTfzY0sQTRgGbkFvL1wO40C/IgJD+aUiGA6hDYmyN+X4mLlhe82MfHHbQzqFMYrY0+nWaMy/gc2xtNUnbW8v/2bM3nhFW86YzBO5n4z7nKWgB31CvQZe+L32vYjfHWv01DfZ5zTTlGSFPwaQdxQ6H4ZxF5Yceng01uchaXu+KVWdf21BGEq9MnyRB76bDUdQhsz6ca+RIUFezsk01DtXwMfj3cG8J31FzjrryfWULzw3/D9407V0Ll/P/m4jhyG+c/Az/9z2lFih0L3S53vAVX8/yVrP/w33hnAOPbjWtNgbQnCVOqX7Wnc/sFyfER447rTibeGbeMt+dkw689O1U7cMLjireoN+lv7GXwy3umhdMVb7v0gzk5xSglVTQrHW/wKzH4Irp7idKmtBSpKEFbpbAAYcEoYn98xiGaN/Ln2zSV8sSLJ2yGZhiqwCVz2qrOM65bv4O0LIX131a7dsxQ+v92ZMHDURPf/ld4k4sSTA0C/W6Fld/j2QadUUst5NEGIyDAR2SQiW0XkwTKO3y4ia0RkpYgsEpFupY495Lpuk4hc6Mk4jSMmPJjP7xhInw7Nufejlbw0dwv1pYRp6qB+t8C4T5xZYt881/nwr8jBHTD1GmjWzvkLvbxeR97k6wfDn4eMPc7Stu6QvhsOrHfPvY7jsSomEfEFNgMXAInAMmCMqq4vdU5TVc10/TwSuENVh7kSxVSgH9AWmAvEqZZMPfl7VsXkPkcKi3noszV8+msil/dpx9NX9CTQr/r1wEcKi9l8IIuubZri61M76ltNHZSy2ZkMMHOvUyo49arfjuVlOgPdNn4NW+Y47RU3f1+rGoHL9Nltv6177u/68gsC/8YQ1NRpfznl7Mrvk7wR3r/MueaPP59Qe4231oPoB2xV1e2uIKYBo4CjCaIkObgEAyXZahQwTVXzgR0istV1v8UejNe4BPj58PxVpxId1pgXvttMYnoub1x3Os0bVzBi1mVnag4LtqSwYHMKi7elkXOkiLvO7cQDQ2vvXDSmlouIg1t+gI/GwWc3Q8oGaN4BNnzljD8oOgKNw53xB/1vr/3JAeDiZ535mXIPOlNxFORCYa7z/cA6eP9yp8ts/Pjy75GYAFOudKZqv+LtE2vMr4QnE0Q7YE+p7USg//EnicidwP1AAHBuqWt/Oe7admVceytwK0CHDh3cErRxiAh3nRdLh7DG/Pnj1Vz+ys9MurEv0eG/1b+qKjvTDrNyzyESdh5i4ZZUdh906lUjQxtxaZ927E3P5bX52xjVu63NDWVOXONQuO4L+Pq+36pmmkc5dfpdhkNkf498QHpMUDMYfH/Zx/IynUb2r+51enNd8MTv323bDzBtnNMmct0XEBrjkTA9WcV0JTBMVW92bV8H9FfVCeWcfy1woareICL/A35R1Q9cx94GvlHVT8p7nlUxec6ynQe5dbLzu33woi4kHcplZWIGq/akk5FbAEBwgC9ndAxjSFwEQ2IjjiaS1Ox8znthPp1bhTDt1gH4nGBV0/aUbH7YmMyYfh0IDqwlk76ZmqcKOxY4CyO16l5ruoq6XVGh09tp6RvQ+WK4/M3fJkRc9wV8erNTAhn36W8jtk+Qt6qYkoDSiyW3d+0rzzTg1RO81nhQ3+hQPr9jEOPfXcZfP12Dj0Dn1k25uGdrerVvTu8OzekU0QS/MkZihzcJ5KGLuvDgZ2v4ZHkio/tWf/3sjNwCbnxnGbsPHubtRTt45JJuDOvR2qYHaYhEqj8iui7y9YOLn3NGcH/7ILwzDMZ85LSzfHWfU2K69iOPT6PuyRKEH04j9Xk4H+7LgGtVdV2pc2JVdYvr5xHAo6oaLyLdgQ/5rZH6eyDWGqm9Kye/kC3J2cS1akLjgKr/bVFcrFz9xmK2JGfz/f1nEdak6msfFxcrt76fwLxNKTw2sjtTluxmw75MzoqL4PGR3Y+p8jKmXto8Bz75gzNHVV6GMzjvqvfcNqeTV8ZBqGohMAGYDWwApqvqOhF5wtVjCWCCiKwTkZU47RA3uK5dB0zHadD+FrizouRgakZwoB+9I5tXKzkA+PgIT13Wk+y8Qv45a2O1rn11/jbmbkjm78O7Mm5AFDMnDOKRS7qxfNchhr64gBfnbiavwP7TMPVY3FC4abbTEN97LFzzYY1N+GcjqU2NeW72Rib+uI0Pb+nPwI6VT8b209ZUrnt7CcNPbcvL1/Q+pkrpQGYeT369gZmr9tKueSP6x4QSEx5MTEQwMeHBRIcFW1uFqV9UPdLmYlNtmFohr6CIof9ZgJ+P8M29gyscW7EvI5dLXl5EaHAAX9w5qNwP+5+2pvLa/G1sTc5mX0beMcfaNAvi0RHdGNajjVvfw5j6xFuN1MYcI8jfl39c2oMbJi3l1XnbuPf8uDLPO1JYzJ1TfiWvoIhXx51eYUlgUKdwBnVySiO5R4rYmZbDjlTn6+vV+7h72kqm3hLE6VEtPPJOxtRnNheTqVFnxUUwoldbXvlxG4u2pJKanf+76Tz+OWsDv+5O59kre9GpZRlrHZejUYAvXds05eKebbjznE58cHN/2jQL4tbJCew5WPvnvTGmtrEqJlPjkrPyuODfC46OoQjy96Ft80a0a96Ipo38+Xr1Pm46M4b/u6RbJXeq3LaUbC6b+BMtmwbx6R8H2noXxhzH2iBMrZOcmcfKPekkpeeyNz2XpPRckg4530/r0IKJY09z2wp3P29L5fq3lzLglDDeGd+3zPuuTcrg2dmbUFUm3Vj2OcbUR5YgTIM3PWEPf/lkNWP6RfLPy3oe7RG15+BhXpiziS9W7iUk0I+s/ELuOS+W+y4ou33EmPrGGqlNgzc6PpKdqTm8Mm8bp4Q34ar49vzvh61MXrwLEbjj7I7cfnZHHvtyHf/7cSvndW3Jqe1PfJTqqj3pRIU1rtIEh8bUVlaCMA1GcbFy19QVzFq7jyaBfuTkF3Ll6e2574I42jRrBDjTegx7cQGNA3z5+u7BBPlXbwK4rLwCHp+5nk+WJ9KskT/3nh/LuAFRJ1xldSjnCIu3pzGse+sTnsfKmIrYinLG4IzofmF0L86Ki6B/TBjf3DOEZ6/sdTQ5ADRr5M+zV57KtpQcnv12U7Xu/8v2NIa9uJDPfk3klsEx9GjXlMdnrueilxYyb1NytePdl5HLla/9zB1TfuWjhD2VX2CMm1kJwpgyPPLlWiYv3lWlUd95BUX8+7vNvLlwO1GhjXlhdG9Oj2qBqjJ3QzJPfb2enWmHObtzBH8f3q1KXXd3pOYw7q0lZOYWEBnamD2HDvP9/WfRsmktXCXN1GnWSG1MNR0+UsjwlxdxpLCYb+8dTEhQ2d1j1+/N5L6PVrLpQBZj+3fgbxd3/d3AviOFxbz3805e/n4LuQVFjOnXgTvO6XhMyeX4e14/aSnFqkz+Qz+CA/248MUFXNC1FRPHnub2dzUNmyUIY07Ar7sPceWrP3Pl6e159speR/dn5hXw3boDzFy9l0VbUmkRHMCzV5zKOV1aVni/tOx8/jN3M9OW7sFHhKv7RvLHszvStvlviSJh50HGv7uMkEA/Jt/U/2hpY+KPW3lu9ibeuj6e87u18swLmwbJEoQxJ6hkgsGXx/QB4KtVe5m3KYUjRcW0a96IS3q14bYhHQkNrnpvpcRDh3ll3jY+TtiD8Fui2Hwgi9s/WE7bZo14/+b+tCuVOI4UFjPiv4vIyitgzv1n0aQaExEmZ+Xxw4Zk5m5IJr+wiB7tmnFqu2b0bN+Mds0b2boaDZwlCGNO0JHCYkZN/IkN+5zl01uGBDL81DaM6NWWPpHNT+rD9fhEoSixLUOYfFM/wstYM2P5rkNc+drP3DgwmkdHdC/3vqrKluRsvlt/gLkbDrByTzqq0K55I5o39mfT/iwKi53/70ODA+jZrhkDTglj3IAO5ValmZqzLSWbqNDGZS7A5QmWIIw5CTtSc/ho2R7O7hxB3+hQfN3c3TQpPZdX520lLfsIz1xxaoXTgTzy5Vre/2UXn98xiN6Rx47TKC5WZq3dx0tzt7AlORuAXu2bcX7XVpzfrRVdWocgIuQVFLFpfxarkzJYk5jO6sQMNu7PIjQ4gAnndGLsgA4VzrRbnuJiZc76/XRqGVKtObRqG1VlbVImXduE1NiHdImPE/bw509WMyQugonX9qmRhG0Jwph6IiuvgAv+vYAWwQHMmDAIf18fVJV5m1N4fvYm1u3NJK5VE24YGM35XVvRqoq9nlYnpvOvbzfy09Y02rdoxP0XxDGqd7sqJ8PF29J4atZ61iZl0jIkkJl3nVnlZ9cmBUXFPPz5GqYnJHLGKWG8PKYPESFVXwHxZPy6+xDXvP4L0eGN2ZaSQ2zLJrwzvm+5nRncxRKEMfXI7HX7ue395Tx4URfio1rw7LebWLrzIJGhjbjv/Op9sB9v4ZYU/vXtRtYmZdKldQj3XxDH4NgIGgWUXaLYkZrD07M2MGf9Ado2C2L8oBj+M3czsa1C+OjWAdUeaOhNOfmF3Pnhr8zblMKIXm2Zs24/zRv788rY0zg9KtSjzz6QmceI/y4iyN+XL+8cxJqkDO6Y8ivBgb5MurEv3ds289izLUEYU8/c9n4C360/QLFCREggd5/biav7diDA7+SrRIqLla/X7OP5OZvYlXYYH4G4ViFO43b7ZvRs5zRuv75gO5MX7yTA14c7zunETWfGEOTvy7dr93P7B8u54rT2PH/VqXWiETwlK58/vLuM9fsyefLSHozp14F1e50P6aRDuTw8vCs3Doz2yLvkFRRx9Ru/sOVAFp/fMYjOrUMA2LAvkz+8u4zM3AImjj2NsztX3EvuRFmCMKae2Z+Rx70frWBIXAQ3Doyu9jrhVVFQVMz8TSmsTkx3tVdkkJZz5OhxH4Gr+0Zy3wVxtAw5tjrpxbmbeXHuFv4+vCs3Dz6l3Gds3J/J9xuSadbIn7DgAEKDAwhrEkhYcADNGvmf9PQimw9k8fSsDexKO8yFPVozqndburRuesw521OyueGdpaRmHWHi2D6c2+W3bsQZuQU8MH0lczckM6JXW565vGe1lrI9lHOEtJx8OrUMKfO4qvLA9FV8tiKJ18adzrAerY85vj8jjz+8u4xNB7L4x6geXNu/QzXevmosQRhjTpqqsjcjjzWJ6WxNzua8rq3o2qZpmecWFyt/nLKc79Yf4N3x/RgSF3HM8YzDBfz7u028/8suisv5CArw9eG0qOYMjo1gUKdwerZrVuWqs0M5R/jP3M1MWbKb4ABferZvxi/bD1JUrMS1asKo3u0Y2astyVn53PzeMnxEmHRjX3pF/n6CxuJi5dX523hhziZOiWjCI5d0Y2DHsAobsPccPMybC7czPWEPeQXF9Ipszo0Do7i4Z5tjOgC8tXA7T369gfvOj+Oe82PLvFd2fiF3TvmV+ZtTGBIXwbmdIzi7c0uiw4Or9LuojNcShIgMA14CfIG3VPWZ447fD9wMFAIpwB9UdZfrWBGwxnXqblUdWdGzLEEYU7vk5Bdy+Ss/sy8jlxkTziQ6PJiiYmV6wh6em72J9MNHGDcgirvPi6W4WEnLOUJatvMX98GcIyQeymXxtjTWu7oYNw3yY2DHcM6MDad726bEhAf/brbcgqJi3l+8ixfnbiY7v5Cx/aO474I4QoMDSMvOZ9aafXy5ci8Juw4B4OcjtG/RiHfH96v0A/enrancM20FqdlHaNHYnwu7t+binm04o2PY0ckY1yZl8PqC7Xy9ei++PsKlvdvRuXUIHy7ZzfbUHMKbBDCmXwfG9o9i84EsbnxnKRd2b83Ea0+rsLRUWFTMyz9sZeaqvexIzQEgJjyYs+IiOLtzBANOCTvh9h6vJAgR8QU2AxcAicAyYIyqri91zjnAElU9LCJ/BM5W1atdx7JVtcp95SxBGFP77E47zMiJiwhvEshjI7rzr283siYpg37RoTw2sjvd2pZdAiktLTufn7al8dOWVBZtTSUpPffosRaN/YkJDyY6PJjIFo35avVetqXkMDg2nL8P73a0Pv94ew4eZubqvexNz+W+8+MIK2PcSVnyCoqYvzmFWWv2MXf9AXKOFNGisT9Du7Vmb0YuC7ek0iTQj7H9OzB+UAytmzlVb8XFyqKtqbz3805+2JSMrwj+vj5EhTXm0z8OrFa11c7UHOZtSmbe5hQWb0sjv7CYLq1D+PbeIVW+R2neShBnAI+p6oWu7YcAVPXpcs7vA/xPVQe5ti1BGFMP/Lw1lesmLaWoWGnVNJC/XdyVkb3anlCDr6qy++BhthzIZkdqDjvSctiRksOO1Bz2Z+YREx7M34d35dwuLT3eOJ5XUMSCzSl87UoWwYF+/OHMGK7t34GmFYxf2JWWwwe/7OLX3em8eHVvIkMbn1QMv2xPI/dIERf1bHNC9/BWgrgSGKaqN7u2rwP6q+qEcs7/H7BfVZ90bRcCK3Gqn55R1S/KuOZW4FaADh06nL5r1y6PvIsx5uTMXLWXbSnZ3Dz4lGpNE1IduUeKCPTz8cq6GQVFxfiIuH0QZU2o9SvKicg4IB44q9TuKFVNEpFTgB9EZI2qbit9naq+AbwBTgmixgI2xlTLiF5tPf6M8sZq1IT6uoa5J98qCYgstd3ete8YInI+8DAwUlXzS/arapLr+3ZgHtDHg7EaY4w5jicTxDIgVkRiRCQAuAaYUfoEV7vD6zjJIbnU/hYiEuj6ORwYBKzHGGNMjfFYFZOqForIBGA2TjfXSaq6TkSeABJUdQbwHNAE+NjVoFTSnbUr8LqIFOMksWdK934yxhjjeTZQzhhjGrCKGqnrZ8uKMcaYk2YJwhhjTJksQRhjjCmTJQhjjDFlqjeN1CKSApzMUOpwINVN4dQl9t4Ni713w1KV945S1YiyDtSbBHGyRCShvJb8+szeu2Gx925YTva9rYrJGGNMmSxBGGOMKZMliN+84e0AvMTeu2Gx925YTuq9rQ3CGGNMmawEYYwxpkyWIIwxxpSpwScIERkmIptEZKuIPOjteDxJRCaJSLKIrC21L1REvhORLa7vLbwZo7uJSKSI/Cgi60VknYjc49pf3987SESWisgq13s/7tofIyJLXP+9f+Sair/eERFfEVkhIl+5thvKe+8U+zCjOgAABJ5JREFUkTUislJEElz7Tvi/9QadIETEF5gIXAR0A8aISDfvRuVR7wLDjtv3IPC9qsYC37u265NC4AFV7QYMAO50/RvX9/fOB85V1V5Ab2CYiAwA/gX8R1U7AYeAm7wYoyfdA2wotd1Q3hvgHNX/b+9uQq2qwjCO/5/MwjSSxCS0EisoArkRCKWBGDUoSQf2QSbSpEkTB1EYRSA47WMQJFRwI/sw85bDzMRyUJkmFeWgJEgx76CsDPrSp8Feh06yq+PVc7ee/fzgcvZeZ7NZL6xz373XPuddHur6/cOYx3qrEwQwD/jK9j7bvwOvAksa7lPf2H4P+P645iXAcNkeBpaOa6f6zPZB27vL9s9U/zRmMvhx2/aRsjux/BlYBGws7QMXN4CkWcBtwHNlX7Qg7v8w5rHe9gQxE/i2a39/aWuTGbYPlu3vgBlNdqafJM2mWrr2Q1oQd5lm2QOMAluAr4HDtv8shwzqeH8KeAg4Vvan0Y64oboIeFvSLkn3l7Yxj/W+rSgXZx7bljSQ33uWNAV4A1hl+6eygiEwuHHbPgoMSZoKjABXNdylvpO0GBi1vUvSwqb704AFtg9IugjYImlv95snOtbbfgdxALika39WaWuTQ5IuBiivo/9z/BlH0kSq5LDe9qbSPPBxd9g+DGwDrgemSupcGA7ieJ8P3C7pG6op40XA0wx+3ADYPlBeR6kuCuZxEmO97QliJ3Bl+YbDOcDdwOaG+zTeNgMry/ZK4K0G+3LKlfnn54EvbT/R9dagxz293DkgaRJwM9Xzl23AsnLYwMVte7XtWbZnU32e37W9nAGPG0DSZEnnd7aBW4DPOYmx3vpfUku6lWrOcgLwgu21DXepbyS9AiykKgF8CHgceBPYAFxKVS79TtvHP8g+Y0laALwPfMbfc9KPUD2HGOS451I9kJxAdSG4wfYaSXOorqwvBD4B7rX9W3M97Z8yxfSg7cVtiLvEOFJ2zwZetr1W0jTGONZbnyAiIqJe26eYIiLiXyRBRERErSSIiIiolQQRERG1kiAiIqJWEkTEaUDSwk7l0YjTRRJERETUSoKIOAGS7i3rLOyRtK4UxDsi6cmy7sJWSdPLsUOSPpD0qaSRTh1+SVdIeqes1bBb0uXl9FMkbZS0V9J6dReMimhAEkREjyRdDdwFzLc9BBwFlgOTgY9tXwNsp/qFOsCLwMO251L9krvTvh54pqzVcAPQqbR5LbCKam2SOVR1hSIak2quEb27CbgO2Fku7idRFT47BrxWjnkJ2CTpAmCq7e2lfRh4vdTKmWl7BMD2rwDlfB/Z3l/29wCzgR39DyuiXhJERO8EDNte/Y9G6bHjjhtr/Zru2kBHyeczGpYppojebQWWlVr7nbV+L6P6HHUqhd4D7LD9I/CDpBtL+wpge1nVbr+kpeUc50o6b1yjiOhRrlAiemT7C0mPUq3YdRbwB/AA8Aswr7w3SvWcAqrSys+WBLAPuK+0rwDWSVpTznHHOIYR0bNUc404SZKO2J7SdD8iTrVMMUVERK3cQURERK3cQURERK0kiIiIqJUEERERtZIgIiKiVhJERETU+gsDdqYfDWH39AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90iCNsImuztS"
      },
      "source": [
        "#3.2 accuracy improvement after adding Local Reponse Normalization\n",
        "#build a model with every setting being the same but LRN removed\n",
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,'relu',False,True,True)\n",
        "model=Model(img_input,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "history_lrn = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=iterations,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#displaying the result for 3.2\n",
        "print('Accuracy improvement in having_lrn vs not_having_lrn is: ' + \n",
        "     str(100*np.min(err_from_acc(history_lrn.history['val_accuracy'])) - 100*np.min(err_from_acc(history.history['val_accuracy']))) \n",
        "     + ' percent' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBCpUvuixYfS"
      },
      "source": [
        "#3.3 accuracy improvement for having overlapping pooling\n",
        "#build a model with every setting being the same but NO overlapping pooling\n",
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,'relu',True,False,True)\n",
        "model=Model(img_input,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "hisotry_overlap = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=iterations,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#displaying the result\n",
        "print('Accuracy improvement in having_overlap vs not_having_overlap is: ' + \n",
        "     str(100*np.min(err_from_acc(hisotry_overlap.history['val_accuracy'])) - 100*np.min(err_from_acc(history.history['val_accuracy']))) \n",
        "     + ' percent' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NREMJDg3gQS"
      },
      "source": [
        "#4.1 data augmentation vs no data augmentation\n",
        "#build a model with every setting being the same but trained with NO data augmentation\n",
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,'relu',True,True,True)\n",
        "model=Model(img_input,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "history_augmentation = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    steps_per_epoch=iterations,\n",
        "    epochs=epochs,\n",
        "    # We pass some validation for\n",
        "    # monitoring validation loss and metrics\n",
        "    # at the end of each epoch\n",
        "    callbacks=cbks,\n",
        "    validation_data=(x_test, y_test),\n",
        ")\n",
        "#displaying the result\n",
        "print('Accuracy improvement in having_augmentation vs not_having_augmentation is: ' + \n",
        "     str(100*np.min(err_from_acc(history_augmentation.history['val_accuracy'])) - 100*np.min(err_from_acc(history.history['val_accuracy']))) \n",
        "     + ' percent' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GnjqMUN3rZG"
      },
      "source": [
        "#4.2 dropout vs no dropout\n",
        "#build a model with every setting being the same but NO dropout\n",
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,'relu',True,True,False)\n",
        "model=Model(img_input,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "hisotry_dropout = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=iterations,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#displaying the result\n",
        "print('Accuracy improvement in having_dropout vs not_having_dropout is: ' + \n",
        "     str(100*np.min(err_from_acc(hisotry_dropout.history['val_accuracy'])) - 100*np.min(err_from_acc(history.history['val_accuracy']))) \n",
        "     + ' percent' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DDxDXk48lP0"
      },
      "source": [
        "# leaky relu vs relu\n",
        "# build a model with every setting being the same but using leaky relu as activation\n",
        "img_input=Input(shape=(32,32,3))\n",
        "output = alexnet(img_input,LeakyReLU(),True,True,False)\n",
        "model=Model(img_input,output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "hisotry_dropout = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=iterations,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test))\n",
        "#displaying the result\n",
        "print('Accuracy improvement in having_dropout vs not_having_dropout is: ' + \n",
        "     str(100*np.min(err_from_acc(hisotry_dropout.history['val_accuracy'])) - 100*np.min(err_from_acc(history.history['val_accuracy']))) \n",
        "     + ' percent' )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}